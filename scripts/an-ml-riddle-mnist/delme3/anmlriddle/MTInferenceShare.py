# automatically generated by the FlatBuffers compiler, do not modify

# namespace: anmlriddle

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class MTInferenceShare(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAsMTInferenceShare(cls, buf, offset):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = MTInferenceShare()
        x.Init(buf, n + offset)
        return x

    # MTInferenceShare
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # MTInferenceShare
    def DShare(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            x = self._tab.Indirect(o + self._tab.Pos)
            from anmlriddle.Matrix import Matrix
            obj = Matrix()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # MTInferenceShare
    def EShare(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = self._tab.Indirect(o + self._tab.Pos)
            from anmlriddle.Matrix import Matrix
            obj = Matrix()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

def MTInferenceShareStart(builder): builder.StartObject(2)
def MTInferenceShareAddDShare(builder, dShare): builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(dShare), 0)
def MTInferenceShareAddEShare(builder, eShare): builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(eShare), 0)
def MTInferenceShareEnd(builder): return builder.EndObject()
